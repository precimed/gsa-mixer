{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from scipy.integrate import quad\n",
    "from scipy.optimize import minimize, basinhopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_z(n, annot, p, s2, s02, r2_het_ss):\n",
    "    z_sample = [random.gauss(0, math.sqrt(s02)) for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        z = 0\n",
    "        for a, r2 in zip(annot,r2_het_ss):\n",
    "            if random.random() < p[a]:\n",
    "                z += random.gauss(0, math.sqrt(s2[a]*r2))\n",
    "        z_sample[i] += z\n",
    "    return z_sample\n",
    "\n",
    "\n",
    "def logistic(x):\n",
    "    \"\"\" Logistic function. Maps [-∞; ∞] -> [0; 1].\n",
    "    \"\"\"\n",
    "    return 1/(1 + math.exp(-x))\n",
    "\n",
    "\n",
    "def logit(x):\n",
    "    \"\"\" Inverse logistic function (logit). Maps [0; 1] -> [-∞; ∞].\n",
    "    \"\"\"\n",
    "    return math.log(x/(1 - x))\n",
    "\n",
    "\n",
    "def ift(x, z, annot, p, s2, s02, r2_het_ss):\n",
    "    res = math.cos(x*z)*math.exp(-0.5*x*x*s02)\n",
    "    for a, r2 in zip(annot, r2_het_ss):\n",
    "        res *= 1-p[a] + p[a]*math.exp(-0.5*x*x*s2[a]*r2)\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_log_likelihood(z_vec, annot, p, s2, s02, r2_het_ss):\n",
    "    log_likelihood = 0\n",
    "    for z in z_vec:\n",
    "        ift_z = lambda x: ift(x, z, annot, p, s2, s02, r2_het_ss)\n",
    "        log_likelihood += -math.log(quad(ift_z, 0, np.inf)[0]/math.pi)\n",
    "    return log_likelihood/len(z_vec)\n",
    "\n",
    "\n",
    "def ift_p(x, z, annot, p, s2, s02, r2_het_ss, p_ind):\n",
    "    \"\"\" (f*g*h)' = f'*g*h + f*g'*h + f*g*h'\n",
    "           der       i0       i1       i2                \n",
    "    \"\"\"\n",
    "    der = 0 # derivative = (f*g*h)'\n",
    "    half_xx = 0.5*x*x\n",
    "    for i in range(len(annot)):\n",
    "        if annot[i] == p_ind:\n",
    "            res = 1\n",
    "            for j, (a, r2) in enumerate(zip(annot, r2_het_ss)):\n",
    "                if j != i:\n",
    "                    res *= 1-p[a] + p[a]*math.exp(-half_xx*s2[a]*r2)\n",
    "                else:\n",
    "                    res *= -1 + math.exp(-half_xx*s2[a]*r2)\n",
    "            der += res\n",
    "    der *= math.cos(x*z)*math.exp(-half_xx*s02)\n",
    "    return der\n",
    "\n",
    "def ift_s2(x, z, annot, p, s2, s02, r2_het_ss, s2_ind):\n",
    "    der = 0\n",
    "    half_xx = 0.5*x*x\n",
    "    for i in range(len(annot)):\n",
    "        if annot[i] == s2_ind:\n",
    "            res = 1\n",
    "            for j, (a, r2) in enumerate(zip(annot, r2_het_ss)):\n",
    "                if j != i:\n",
    "                    res *= 1-p[a] + p[a]*math.exp(-half_xx*s2[a]*r2)\n",
    "                else:\n",
    "                    res *= p[a]*math.exp(-half_xx*s2[a]*r2)*(-half_xx*r2)\n",
    "            der += res\n",
    "    der *= math.cos(x*z)*math.exp(-half_xx*s02)\n",
    "    return der\n",
    "\n",
    "def ift_s02(x, z, annot, p, s2, s02, r2_het_ss):\n",
    "    der = math.cos(x*z)*math.exp(-0.5*x*x*s02)*(-0.5*x*x)\n",
    "    for a, r2 in zip(annot, r2_het_ss):\n",
    "        der *= 1-p[a] + p[a]*math.exp(-0.5*x*x*s2[a]*r2)\n",
    "    return der\n",
    "\n",
    "\n",
    "def get_log_likelihood_derivative(z_vec, annot, p, s2, s02, r2_het_ss):\n",
    "    \"\"\" \n",
    "    assume we have n anootation categories and f is our likelihood function, then:\n",
    "    gradient = [f_p1, f_p2, ..., f_pn, f_s21, f_s22, ..., f_s2n, f_s02], f = -log_likelihood\n",
    "    f' = [-log(g)]' = -(1/g * g'), g = likelihood\n",
    "    \"\"\"\n",
    "    n_annot = len(set(annot))\n",
    "    gradient = [0 for _ in range(2*n_annot+1)]\n",
    "        \n",
    "    for z in z_vec:\n",
    "        ift_z = lambda x: ift(x, z, annot, p, s2, s02, r2_het_ss)\n",
    "        likelihood_z = quad(ift_z, 0, np.inf)[0]/math.pi\n",
    "        for i in range(n_annot):\n",
    "            # get p derivative\n",
    "            ift_z_pi = lambda x: ift_p(x, z, annot, p, s2, s02, r2_het_ss, i)\n",
    "            likelihood_z_pi = quad(ift_z_pi, 0, np.inf)[0]/math.pi\n",
    "            gradient[i] += -likelihood_z_pi/likelihood_z\n",
    "            \n",
    "            # get s2 derivative\n",
    "            ift_z_s2i = lambda x: ift_s2(x, z, annot, p, s2, s02, r2_het_ss, i)\n",
    "            likelihood_z_s2i = quad(ift_z_s2i, 0, np.inf)[0]/math.pi\n",
    "            gradient[i+n_annot] += -likelihood_z_s2i/likelihood_z\n",
    "        # get s02 derivative\n",
    "        ift_z_s02 = lambda x: ift_s02(x, z, annot, p, s2, s02, r2_het_ss)\n",
    "        likelihood_z_s02 = quad(ift_z_s02, 0, np.inf)[0]/math.pi\n",
    "        gradient[-1] += -likelihood_z_s02/likelihood_z\n",
    "    # devide all elements of gradient by len(z_vec)    \n",
    "    return np.array([x/len(z_vec) for x in gradient])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29829209 0.11311471 0.20833627 0.04797487 0.05136496]\n"
     ]
    }
   ],
   "source": [
    "# test _cmmcost_omp with z2use = {true, false, false}\n",
    "z_vec = [1.275]\n",
    "annot = [0,1,0]\n",
    "r2_het_ss = [1.593, 0.934, 2.463]\n",
    "p = [1, 1]\n",
    "s2 = [1.17, 2.03]\n",
    "s02 = 1.03\n",
    "\n",
    "gradient = get_log_likelihood_derivative(z_vec, annot, p, s2, s02, r2_het_ss)\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot = [0, 0, 0, 0] # [0, 0, 0, 0, 0]\n",
    "r2_het_ss = [3421, 6436, 10234, 554, 9257] # [1, 1, 1, 1, 1] # [3421, 6436, 10234, 554, 9257]\n",
    "p =  [0.4]\n",
    "s2 = [1E-4]\n",
    "s02 = 1.0\n",
    "n_z_samples = 4000\n",
    "assert len(set(annot)) == len(p) == len(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_sample = sample_z(n_z_samples, annot, p, s2, s02, r2_het_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 0.021350377436065927\n",
      "std =  1.3445206756011023\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(z_sample,50,density=True)\n",
    "x = np.linspace(min(z_sample), max(z_sample), 100)\n",
    "plt.plot(x, norm.pdf(x, 0, math.sqrt(s02)), 'r', lw=1, label='pdf')\n",
    "print(f\"mean = {np.mean(z_sample)}\\nstd =  {np.std(z_sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimum likelihood = 1.7151117535333056\n",
      "optimized likelihood = 5.631253285333626\n",
      "[ 3.17440327e-04  2.66930414e+01 -1.29032125e-03]\n"
     ]
    }
   ],
   "source": [
    "p_in_opt = [1]\n",
    "s2_in_opt = [0.6]\n",
    "z_vec = z_sample # [0.5] # z_sample\n",
    "l_opt = get_log_likelihood(z_vec, annot, p, s2, s02, r2_het_ss)\n",
    "l1 = get_log_likelihood(z_vec, annot, p_in_opt, s2_in_opt, s02, r2_het_ss)\n",
    "print(f\"optimum likelihood = {l_opt}\")\n",
    "print(f\"optimized likelihood = {l1}\")\n",
    "gradient = get_log_likelihood_derivative(z_vec, annot, p, s2, s02, r2_het_ss)\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optmization\n",
    "p_init = p\n",
    "s2_init = s2\n",
    "s02_init = s02\n",
    "\n",
    "# p_init = [0.8] # [random.random() for _ in p]\n",
    "# s2_init = [1E-3] # [random.random() for _ in s2]\n",
    "# s02_init = 1.1 # random.random()\n",
    "\n",
    "def cost_func(x, z_sample, annot, r2_het_ss):\n",
    "    \"\"\" x = p + s2 + s02\n",
    "    \"\"\"\n",
    "    n_annot = len(set(annot))\n",
    "    p_in_opt = [logistic(y) for y in x[:n_annot]]\n",
    "    s2_in_opt = [math.exp(y) for y in x[n_annot:-1]]\n",
    "    s02_in_opt = math.exp(x[-1])\n",
    "    minus_log_lik = get_log_likelihood(z_sample, annot, p_in_opt, s2_in_opt, s02_in_opt, r2_het_ss)\n",
    "    print(p_in_opt,s2_in_opt,s02_in_opt,minus_log_lik)\n",
    "    return minus_log_lik\n",
    "\n",
    "def grad_func(x, z_sample, annot, r2_het_ss):\n",
    "    \"\"\" x = p + s2 + s02\n",
    "    \"\"\"\n",
    "    n_annot = len(set(annot))\n",
    "    p_in_opt = [logistic(y) for y in x[:n_annot]]\n",
    "    s2_in_opt = [math.exp(y) for y in x[n_annot:-1]]\n",
    "    s02_in_opt = math.exp(x[-1])\n",
    "    grad = get_log_likelihood_derivative(z_sample, annot, p_in_opt, s2_in_opt, s02_in_opt, r2_het_ss)\n",
    "    \n",
    "    # [1/(1 + math.exp(-x))]' = math.exp(-x)/(1 + math.exp(-x))**2\n",
    "    p_transform_der = [math.exp(-y)/(1 + math.exp(-y))**2 for y in x[:n_annot]]\n",
    "    s2_transform_der = [math.exp(y) for y in x[n_annot:-1]]\n",
    "    s02_transform_der = [math.exp(x[-1])]\n",
    "    transform_der = p_transform_der + s2_transform_der + s02_transform_der\n",
    "    grad = np.array([g*d for g,d in zip(grad, transform_der)])\n",
    "   \n",
    "    print(f\"gradient: {grad}\")\n",
    "    return grad\n",
    "\n",
    "p_init_in_opt = [logit(y) for y in p_init]\n",
    "s2_init_in_opt = [math.log(y) for y in s2_init]\n",
    "s02_init_in_opt = [math.log(s02_init)]\n",
    "\n",
    "x_init_in_opt = p_init_in_opt + s2_init_in_opt + s02_init_in_opt\n",
    "\n",
    "# res_nm = minimize(cost_func, x_init_in_opt, args=(z_sample, annot, r2_het_ss), method='Nelder-Mead',\n",
    "#                options={\"maxiter\":50, \"fatol\":1E-2, \"xatol\":1E-5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient: [ 7.61856785e-05  2.66930414e-03 -1.29032125e-03]\n",
      "[0.4] [0.00010000000000000009] 1.0 1.7151117535333056\n",
      "[0.3999817155764764] [9.97334255282559e-05] 1.001291154068875 1.7151030437942152\n",
      "gradient: [ 2.75518151e-05  2.56355353e-03 -1.37866753e-03]\n",
      "[0.39990858066935914] [9.867421491811173e-05] 1.006472462671126 1.7150698908727189\n",
      "gradient: [-0.00016163  0.00215029 -0.00172907]\n",
      "[0.3996160856848073] [9.454867667820603e-05] 1.0274672014730442 1.71496178721215\n",
      "gradient: [-0.00083443  0.00065137 -0.00307696]\n",
      "[0.3994071536396528] [8.436551710413212e-05] 1.0940579778373944 1.714767307419681\n",
      "gradient: [-0.00142892 -0.00129023 -0.00458011]\n",
      "[0.3996059232918868] [7.365734548920146e-05] 1.1879055702041739 1.7146158048360258\n",
      "gradient: [-0.00069468 -0.00090245 -0.00267273]\n",
      "[0.39978910193951966] [6.507926199481402e-05] 1.282064506342932 1.714594978429007\n",
      "gradient: [0.00058102 0.00078043 0.00219905]\n",
      "[0.3997037382176686] [6.865734752234275e-05] 1.2403437717512213 1.7145837522251353\n",
      "gradient: [-1.99644538e-05 -6.25109339e-05 -3.03323031e-04]\n",
      "[0.39969898324146097] [6.795675940534694e-05] 1.2479775366365509 1.7145830407175544\n",
      "gradient: [7.73701589e-05 6.63873801e-05 7.98069659e-05]\n"
     ]
    }
   ],
   "source": [
    "# res_nm = minimize(cost_func, x_init_in_opt, args=(z_sample, annot, r2_het_ss), method='Nelder-Mead',\n",
    "#                options={\"maxiter\":50, \"fatol\":1E-2, \"xatol\":1E-5})\n",
    "res_bfgs = minimize(cost_func, x_init_in_opt, args=(z_sample, annot, r2_het_ss), method='BFGS',\n",
    "               jac=grad_func, options={\"maxiter\":20, \"gtol\":1E-4}) # , \"norm\":2.\n",
    "\n",
    "# minimizer_kwargs = {\"args\":(z_sample, annot, r2_het_ss), \"method\": \"Nelder-Mead\", \"options\":{\"maxiter\":10}}\n",
    "# res_basin = basinhopping(cost_func, x_init_in_opt, niter=20,minimizer_kwargs=minimizer_kwargs)\n",
    "\n",
    "# minimizer_kwargs = {\"args\":(z_sample, annot, r2_het_ss), \"method\": \"BFGS\", \"jac\":grad_func,\n",
    "#                     \"options\":{\"maxiter\":5}}\n",
    "# res_basin = basinhopping(cost_func, x_init_in_opt, niter=20,minimizer_kwargs=minimizer_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        fun: 1.7057695531489812\n",
      " lowest_optimization_result:  final_simplex: (array([[ 8.05554434e-01, -9.78798284e+00, -1.08785781e-03],\n",
      "       [ 8.22611694e-01, -9.79110554e+00, -1.07341677e-03],\n",
      "       [ 8.14804147e-01, -9.84868987e+00, -1.05138089e-03],\n",
      "       [ 8.13725418e-01, -9.85157236e+00, -1.08380310e-03]]), array([1.70576955, 1.70579141, 1.70581887, 1.70582899]))\n",
      "           fun: 1.7057695531489812\n",
      "       message: 'Maximum number of iterations has been exceeded.'\n",
      "          nfev: 21\n",
      "           nit: 10\n",
      "        status: 2\n",
      "       success: False\n",
      "             x: array([ 8.05554434e-01, -9.78798284e+00, -1.08785781e-03])\n",
      "                    message: ['requested number of basinhopping iterations completed successfully']\n",
      "      minimization_failures: 21\n",
      "                       nfev: 425\n",
      "                        nit: 20\n",
      "                          x: array([ 8.05554434e-01, -9.78798284e+00, -1.08785781e-03])\n",
      "[0.6911613730321382] [5.6121990474486066e-05] 0.9989127336954803\n"
     ]
    }
   ],
   "source": [
    "res = res_basin\n",
    "print(res)\n",
    "n_annot = len(set(annot))\n",
    "p_in_opt = [logistic(y) for y in res.x[:n_annot]]\n",
    "s2_in_opt = [math.exp(y) for y in res.x[n_annot:-1]]\n",
    "s02_in_opt = math.exp(res.x[-1])\n",
    "print(p_in_opt, s2_in_opt, s02_in_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 1.7145830407175544\n",
      " hess_inv: array([[  0.99141755,   0.26499002,  -0.18519934],\n",
      "       [  0.26499002,  94.66431233, -53.34045451],\n",
      "       [ -0.18519934, -53.34045451,  31.23321301]])\n",
      "      jac: array([7.73701589e-05, 6.63873801e-05, 7.98069659e-05])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 9\n",
      "      nit: 6\n",
      "     njev: 9\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([-0.4067195 , -9.59663895,  0.22152427])\n",
      "[0.39969898324146097] [6.795675940534694e-05] 1.2479775366365509\n",
      "Optimal: [0.4] [0.0001] 1.0\n"
     ]
    }
   ],
   "source": [
    "print(res_bfgs)\n",
    "n_annot = len(set(annot))\n",
    "p_in_opt = [logistic(y) for y in res_bfgs.x[:n_annot]]\n",
    "s2_in_opt = [math.exp(y) for y in res_bfgs.x[n_annot:-1]]\n",
    "s02_in_opt = math.exp(res_bfgs.x[-1])\n",
    "print(p_in_opt, s2_in_opt, s02_in_opt)\n",
    "print(f\"Optimal: {p} {s2} {s02}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = 2\n",
    "x = 0.5\n",
    "normal_pdf_der = lambda x: -(math.pi/(math.sqrt(2*math.pi*s2))**3)*math.exp(-x*x/(2*s2)) + \\\n",
    "                                  (math.exp(-x*x/(2*s2))/math.sqrt(2*math.pi*s2))*(x*x/(2*s2*s2))\n",
    "normal_pdf_der1 = lambda x: (math.exp(-x*x/(2*s2))/math.sqrt(2*math.pi*s2))*(x*x/(2*s2*s2) - 1/(2*s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.057969522700256265, -0.05796952270025625)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_pdf_der(x), normal_pdf_der1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.057969335076624155"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(norm.pdf(x,0,math.sqrt(s2+1E-5)) - norm.pdf(x,0,math.sqrt(s2)))/1E-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21875"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-normal_pdf_der1(x)/norm.pdf(x,0,math.sqrt(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient: [1.356751518275716, 0.2422887974812564, 0.1300191125852796]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.356751518275716, 0.2422887974812564, 0.1300191125852796]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_func(p+s2+[s02], z_sample, annot, r2_het_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood derivative sb2[0] = 0.07922259969273605\n",
      "Likelihood derivative sb2[1] = 0.08021267602154018\n",
      "Likelihood derivative sb2[2] = 0.025791314143875393\n",
      "Likelihood derivative s02 = 0.049707571334653616\n"
     ]
    }
   ],
   "source": [
    "# Test from _cmmcost_omp.c with z2use = {true, true, true}\n",
    "def normal_pdf_derivative(x, s2):\n",
    "    return (math.exp(-x*x/(2*s2))/math.sqrt(2*math.pi*s2))*(x*x/(2*s2*s2) - 1/(2*s2))\n",
    "z_vec = [1.275, -0.496, 2.983]\n",
    "# SNP   S2_eff (see _cmmcost_omp.c, main())\n",
    "# 0     1.593*1.17 + 0.934*2.03 + 2.463*1.17 + 1.03 = 7.671539999999999\n",
    "# 1     0.719*0.954 + 1.847*2.03 + 1.03 = 5.465336\n",
    "# 2     3.012*2.03 + 1.927*1.17 + 0.896*1.17 + 1.401*0.954 + 1.03 = 11.783824\n",
    "#\n",
    "# sb2 = {1.17, 2.03, 0.954}\n",
    "s2_eff_vec = [7.671539999999999, 5.465336, 11.783824]\n",
    "likelihood_der_sb2_0 = 0\n",
    "likelihood_der_sb2_0 += -(1.593 + 2.463)*normal_pdf_derivative(z_vec[0], s2_eff_vec[0])/norm.pdf(z_vec[0],0,math.sqrt(s2_eff_vec[0]))\n",
    "likelihood_der_sb2_0 += -(1.927 + 0.896)*normal_pdf_derivative(z_vec[2], s2_eff_vec[2])/norm.pdf(z_vec[2],0,math.sqrt(s2_eff_vec[2]))\n",
    "likelihood_der_sb2_0 /= 3\n",
    "print(f\"Likelihood derivative sb2[0] = {likelihood_der_sb2_0}\")\n",
    "\n",
    "likelihood_der_sb2_1 = 0\n",
    "likelihood_der_sb2_1 += -(0.934)*normal_pdf_derivative(z_vec[0], s2_eff_vec[0])/norm.pdf(z_vec[0],0,math.sqrt(s2_eff_vec[0]))\n",
    "likelihood_der_sb2_1 += -(1.847)*normal_pdf_derivative(z_vec[1], s2_eff_vec[1])/norm.pdf(z_vec[1],0,math.sqrt(s2_eff_vec[1]))\n",
    "likelihood_der_sb2_1 += -(3.012)*normal_pdf_derivative(z_vec[2], s2_eff_vec[2])/norm.pdf(z_vec[2],0,math.sqrt(s2_eff_vec[2]))\n",
    "likelihood_der_sb2_1 /= 3\n",
    "print(f\"Likelihood derivative sb2[1] = {likelihood_der_sb2_1}\")\n",
    "\n",
    "likelihood_der_sb2_2 = 0\n",
    "likelihood_der_sb2_2 += -(0.719)*normal_pdf_derivative(z_vec[1], s2_eff_vec[1])/norm.pdf(z_vec[1],0,math.sqrt(s2_eff_vec[1]))\n",
    "likelihood_der_sb2_2 += -(1.401)*normal_pdf_derivative(z_vec[2], s2_eff_vec[2])/norm.pdf(z_vec[2],0,math.sqrt(s2_eff_vec[2]))\n",
    "likelihood_der_sb2_2 /= 3\n",
    "print(f\"Likelihood derivative sb2[2] = {likelihood_der_sb2_2}\")\n",
    "\n",
    "likelihood_der_s02 = 0\n",
    "likelihood_der_s02 += -normal_pdf_derivative(z_vec[0], s2_eff_vec[0])/norm.pdf(z_vec[0],0,math.sqrt(s2_eff_vec[0]))\n",
    "likelihood_der_s02 += -normal_pdf_derivative(z_vec[1], s2_eff_vec[1])/norm.pdf(z_vec[1],0,math.sqrt(s2_eff_vec[1]))\n",
    "likelihood_der_s02 += -normal_pdf_derivative(z_vec[2], s2_eff_vec[2])/norm.pdf(z_vec[2],0,math.sqrt(s2_eff_vec[2]))\n",
    "likelihood_der_s02 /= 3\n",
    "print(f\"Likelihood derivative s02 = {likelihood_der_s02}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.279812543885835e-12"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.cdf(-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
